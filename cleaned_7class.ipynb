{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-08-18T11:59:07.273709Z",
     "iopub.status.busy": "2023-08-18T11:59:07.273258Z",
     "iopub.status.idle": "2023-08-18T11:59:09.380947Z",
     "shell.execute_reply": "2023-08-18T11:59:09.377754Z"
    }
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "from qiskit import QuantumCircuit\n",
    "from qiskit.algorithms.optimizers import COBYLA\n",
    "from qiskit.circuit import ParameterVector\n",
    "from qiskit.circuit.library import ZFeatureMap\n",
    "from qiskit.quantum_info import SparsePauliOp\n",
    "from qiskit.utils import algorithm_globals\n",
    "from qiskit_machine_learning.algorithms.classifiers import NeuralNetworkClassifier\n",
    "from qiskit_machine_learning.neural_networks import EstimatorQNN\n",
    "from sklearn.model_selection import train_test_split\n",
    "import os\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "algorithm_globals.random_seed = 12345\n",
    "\n",
    "# We now define a two qubit unitary as defined in [3]\n",
    "def conv_circuit(params):\n",
    "    target = QuantumCircuit(2)\n",
    "    target.rz(-np.pi / 2, 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(params[0], 0)\n",
    "    target.ry(params[1], 1)\n",
    "    target.cx(0, 1)\n",
    "    target.ry(params[2], 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(np.pi / 2, 0)\n",
    "    return target\n",
    "\n",
    "def conv_layer(num_qubits, param_prefix):\n",
    "    qc = QuantumCircuit(num_qubits, name=\"Convolutional Layer\")\n",
    "    qubits = list(range(num_qubits))\n",
    "    param_index = 0\n",
    "    params = ParameterVector(param_prefix, length=num_qubits * 3)\n",
    "    for q1, q2 in zip(qubits[0::2], qubits[1::2]):\n",
    "        qc = qc.compose(conv_circuit(params[param_index : (param_index + 3)]), [q1, q2])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "    for q1, q2 in zip(qubits[1::2], qubits[2::2] + [0]):\n",
    "        qc = qc.compose(conv_circuit(params[param_index : (param_index + 3)]), [q1, q2])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "\n",
    "    qc_inst = qc.to_instruction()\n",
    "\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    qc.append(qc_inst, qubits)\n",
    "    return qc\n",
    "\n",
    "def pool_circuit(params):\n",
    "    target = QuantumCircuit(2)\n",
    "    target.rz(-np.pi / 2, 1)\n",
    "    target.cx(1, 0)\n",
    "    target.rz(params[0], 0)\n",
    "    target.ry(params[1], 1)\n",
    "    target.cx(0, 1)\n",
    "    target.ry(params[2], 1)\n",
    "\n",
    "    return target\n",
    "\n",
    "def pool_layer(sources, sinks, param_prefix):\n",
    "    num_qubits = len(sources) + len(sinks)\n",
    "    qc = QuantumCircuit(num_qubits, name=\"Pooling Layer\")\n",
    "    param_index = 0\n",
    "    params = ParameterVector(param_prefix, length=num_qubits // 2 * 3)\n",
    "    for source, sink in zip(sources, sinks):\n",
    "        qc = qc.compose(pool_circuit(params[param_index : (param_index + 3)]), [source, sink])\n",
    "        qc.barrier()\n",
    "        param_index += 3\n",
    "\n",
    "    qc_inst = qc.to_instruction()\n",
    "\n",
    "    qc = QuantumCircuit(num_qubits)\n",
    "    qc.append(qc_inst, range(num_qubits))\n",
    "    return qc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a678692",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Feature map for 64 qubits suitable for the image size\n",
    "feature_map_64 = ZFeatureMap(64)\n",
    "\n",
    "# Three alternating conv_layer and pool_layer functions\n",
    "conv_layer_1 = conv_layer(64, \"conv_params_1\")\n",
    "pool_layer_1 = pool_layer(range(0, 32), range(32, 64), \"pool_params_1\")\n",
    "\n",
    "conv_layer_2 = conv_layer(64, \"conv_params_2\")\n",
    "pool_layer_2 = pool_layer(range(0, 32), range(32, 64), \"pool_params_2\")\n",
    "\n",
    "conv_layer_3 = conv_layer(64, \"conv_params_3\")\n",
    "pool_layer_3 = pool_layer(range(0, 32), range(32, 64), \"pool_params_3\")\n",
    "\n",
    "# Combine the layers to form the complete quantum circuit\n",
    "circuit_64_3layers = QuantumCircuit(64)\n",
    "circuit_64_3layers.compose(feature_map_64, range(64), inplace=True)\n",
    "circuit_64_3layers.compose(conv_layer_1, range(64), inplace=True)\n",
    "circuit_64_3layers.compose(pool_layer_1, range(64), inplace=True)\n",
    "circuit_64_3layers.compose(conv_layer_2, range(64), inplace=True)\n",
    "circuit_64_3layers.compose(pool_layer_2, range(64), inplace=True)\n",
    "circuit_64_3layers.compose(conv_layer_3, range(64), inplace=True)\n",
    "circuit_64_3layers.compose(pool_layer_3, range(64), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths to your train data folders\n",
    "train_data_dir = 'test'\n",
    "\n",
    "# Set image dimensions and batch size\n",
    "img_width, img_height = 48,48\n",
    "batch_size = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 7178 images belonging to 7 classes.\n",
      "Class Indices: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
      "X_train shape: (7178, 48, 48, 3)\n",
      "Y_train_one_hot shape: (7178, 7, 7)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\"\\nOutput:\\nFound 28709 images belonging to 7 classes.\\nClass Indices: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\\nX_train shape: (28709, 128, 128, 3)\\nY_train_one_hot shape: (28709, 7, 7)\\n\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an ImageDataGenerator for data preprocessing and augmentation\n",
    "datagen = ImageDataGenerator(\n",
    "    rescale=1.0 / 255.0,\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")\n",
    "\n",
    "# Generate training data\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True,\n",
    "    color_mode='rgb'\n",
    ")\n",
    "\n",
    "# Extract X_train (input images) and Y_train (labels)\n",
    "X_train = []\n",
    "Y_train = []\n",
    "\n",
    "for images, labels in train_generator:\n",
    "    X_train.extend(images)\n",
    "    Y_train.extend(labels)\n",
    "    \n",
    "    if len(X_train) >= len(train_generator.filenames):\n",
    "        break\n",
    "\n",
    "X_train = np.array(X_train)\n",
    "Y_train = np.array(Y_train)\n",
    "\n",
    "# Print class labels and their corresponding indices\n",
    "class_indices = train_generator.class_indices\n",
    "print(\"Class Indices:\", class_indices)\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "num_classes = len(class_indices)\n",
    "Y_train_one_hot = tf.keras.utils.to_categorical(Y_train, num_classes=num_classes)\n",
    "\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "print(\"Y_train_one_hot shape:\", Y_train_one_hot.shape)\n",
    "\n",
    "'''\n",
    "Output:\n",
    "Found 7178 images belonging to 7 classes.\n",
    "Class Indices: {'angry': 0, 'disgust': 1, 'fear': 2, 'happy': 3, 'neutral': 4, 'sad': 5, 'surprise': 6}\n",
    "X_train shape: (7178, 48, 48, 3)\n",
    "Y_train_one_hot shape: (7178, 7, 7)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1485ca88",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7178, 8)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Confirming the images are grayscale by checking if all channels have the same values\n",
    "assert np.all(X_train[:,:,:,0] == X_train[:,:,:,1]) and np.all(X_train[:,:,:,0] == X_train[:,:,:,2])\n",
    "\n",
    "# Dropping the redundant channels\n",
    "X_train = X_train[:,:,:,0]\n",
    "\n",
    "# Flattening the images\n",
    "X_train_flat = X_train.reshape(X_train.shape[0], -1)\n",
    "\n",
    "# Applying PCA\n",
    "pca = PCA(n_components=8)\n",
    "X_train_pca = pca.fit_transform(X_train_flat)\n",
    "\n",
    "X_train_pca.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7a00f044",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((7178, 48, 48), (7178, 7, 7))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Assuming the necessary libraries and functions have been imported previously\n",
    "# Extracting the shape of X_train and Y_train_one_hot\n",
    "X_train_shape = X_train.shape\n",
    "Y_train_one_hot_shape = Y_train_one_hot.shape\n",
    "\n",
    "X_train_shape, Y_train_one_hot_shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def callback_graph(weights, obj_func_eval):\n",
    "    clear_output(wait=True)\n",
    "    objective_func_vals.append(obj_func_eval)\n",
    "    plt.title(\"Objective function value against iteration\")\n",
    "    plt.xlabel(\"Iteration\")\n",
    "    plt.ylabel(\"Objective function value\")\n",
    "    plt.plot(range(len(objective_func_vals)), objective_func_vals)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "capi_return is NULL\n",
      "Call-back cb_calcfc_in__cobyla__user__routines failed.\n"
     ]
    },
    {
     "ename": "QiskitMachineLearningError",
     "evalue": "'Input data has incorrect shape, last dimension is not equal to the number of inputs: 8, but got: 3.'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mQiskitMachineLearningError\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m/Users/avyarathod/Desktop/Coding shit/Quantum/test.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/avyarathod/Desktop/Coding%20shit/Quantum/test.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m objective_func_vals \u001b[39m=\u001b[39m []\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/avyarathod/Desktop/Coding%20shit/Quantum/test.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mrcParams[\u001b[39m\"\u001b[39m\u001b[39mfigure.figsize\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m (\u001b[39m12\u001b[39m, \u001b[39m6\u001b[39m)\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/avyarathod/Desktop/Coding%20shit/Quantum/test.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m classifier\u001b[39m.\u001b[39;49mfit(X_train, Y_train_one_hot)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/avyarathod/Desktop/Coding%20shit/Quantum/test.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39m# score classifier\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/avyarathod/Desktop/Coding%20shit/Quantum/test.ipynb#W5sZmlsZQ%3D%3D?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mAccuracy from the train data : \u001b[39m\u001b[39m{\u001b[39;00mnp\u001b[39m.\u001b[39mround(\u001b[39m100\u001b[39m \u001b[39m*\u001b[39m classifier\u001b[39m.\u001b[39mscore(x, y), \u001b[39m2\u001b[39m)\u001b[39m}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/seg_models/lib/python3.9/site-packages/qiskit_machine_learning/algorithms/trainable_model.py:199\u001b[0m, in \u001b[0;36mTrainableModel.fit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    196\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_warm_start:\n\u001b[1;32m    197\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_result \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m--> 199\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fit_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_internal(X, y)\n\u001b[1;32m    200\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/seg_models/lib/python3.9/site-packages/qiskit_machine_learning/algorithms/classifiers/neural_network_classifier.py:115\u001b[0m, in \u001b[0;36mNeuralNetworkClassifier._fit_internal\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    112\u001b[0m X, y \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_input(X, y)\n\u001b[1;32m    114\u001b[0m function \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_create_objective(X, y)\n\u001b[0;32m--> 115\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_minimize(function)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/seg_models/lib/python3.9/site-packages/qiskit_machine_learning/algorithms/trainable_model.py:295\u001b[0m, in \u001b[0;36mTrainableModel._minimize\u001b[0;34m(self, function)\u001b[0m\n\u001b[1;32m    291\u001b[0m     optimizer_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_optimizer(\n\u001b[1;32m    292\u001b[0m         fun\u001b[39m=\u001b[39mobjective, x0\u001b[39m=\u001b[39minitial_point, jac\u001b[39m=\u001b[39mfunction\u001b[39m.\u001b[39mgradient\n\u001b[1;32m    293\u001b[0m     )\n\u001b[1;32m    294\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m--> 295\u001b[0m     optimizer_result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_optimizer\u001b[39m.\u001b[39;49mminimize(\n\u001b[1;32m    296\u001b[0m         fun\u001b[39m=\u001b[39;49mobjective,\n\u001b[1;32m    297\u001b[0m         x0\u001b[39m=\u001b[39;49minitial_point,\n\u001b[1;32m    298\u001b[0m         jac\u001b[39m=\u001b[39;49mfunction\u001b[39m.\u001b[39;49mgradient,\n\u001b[1;32m    299\u001b[0m     )\n\u001b[1;32m    300\u001b[0m \u001b[39mreturn\u001b[39;00m optimizer_result\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/seg_models/lib/python3.9/site-packages/qiskit/algorithms/optimizers/scipy_optimizer.py:149\u001b[0m, in \u001b[0;36mSciPyOptimizer.minimize\u001b[0;34m(self, fun, x0, jac, bounds)\u001b[0m\n\u001b[1;32m    146\u001b[0m     swapped_deprecated_args \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options[\u001b[39m\"\u001b[39m\u001b[39mmaxfun\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mmaxiter\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> 149\u001b[0m raw_result \u001b[39m=\u001b[39m minimize(\n\u001b[1;32m    150\u001b[0m     fun\u001b[39m=\u001b[39;49mfun,\n\u001b[1;32m    151\u001b[0m     x0\u001b[39m=\u001b[39;49mx0,\n\u001b[1;32m    152\u001b[0m     method\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_method,\n\u001b[1;32m    153\u001b[0m     jac\u001b[39m=\u001b[39;49mjac,\n\u001b[1;32m    154\u001b[0m     bounds\u001b[39m=\u001b[39;49mbounds,\n\u001b[1;32m    155\u001b[0m     options\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_options,\n\u001b[1;32m    156\u001b[0m     \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_kwargs,\n\u001b[1;32m    157\u001b[0m )\n\u001b[1;32m    158\u001b[0m \u001b[39mif\u001b[39;00m swapped_deprecated_args:\n\u001b[1;32m    159\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options[\u001b[39m\"\u001b[39m\u001b[39mmaxiter\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_options\u001b[39m.\u001b[39mpop(\u001b[39m\"\u001b[39m\u001b[39mmaxfun\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/seg_models/lib/python3.9/site-packages/scipy/optimize/_minimize.py:629\u001b[0m, in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    626\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_tnc(fun, x0, args, jac, bounds, callback\u001b[39m=\u001b[39mcallback,\n\u001b[1;32m    627\u001b[0m                          \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n\u001b[1;32m    628\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mcobyla\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[0;32m--> 629\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_cobyla(fun, x0, args, constraints, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49moptions)\n\u001b[1;32m    630\u001b[0m \u001b[39melif\u001b[39;00m meth \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mslsqp\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    631\u001b[0m     \u001b[39mreturn\u001b[39;00m _minimize_slsqp(fun, x0, args, jac, bounds,\n\u001b[1;32m    632\u001b[0m                            constraints, callback\u001b[39m=\u001b[39mcallback, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39moptions)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/seg_models/lib/python3.9/site-packages/scipy/optimize/cobyla.py:34\u001b[0m, in \u001b[0;36msynchronized.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     32\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mwrapper\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     33\u001b[0m     \u001b[39mwith\u001b[39;00m _module_lock:\n\u001b[0;32m---> 34\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/seg_models/lib/python3.9/site-packages/scipy/optimize/cobyla.py:260\u001b[0m, in \u001b[0;36m_minimize_cobyla\u001b[0;34m(fun, x0, args, constraints, rhobeg, tol, maxiter, disp, catol, **unknown_options)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[39mreturn\u001b[39;00m f\n\u001b[1;32m    259\u001b[0m info \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mzeros(\u001b[39m4\u001b[39m, np\u001b[39m.\u001b[39mfloat64)\n\u001b[0;32m--> 260\u001b[0m xopt, info \u001b[39m=\u001b[39m _cobyla\u001b[39m.\u001b[39;49mminimize(calcfc, m\u001b[39m=\u001b[39;49mm, x\u001b[39m=\u001b[39;49mnp\u001b[39m.\u001b[39;49mcopy(x0), rhobeg\u001b[39m=\u001b[39;49mrhobeg,\n\u001b[1;32m    261\u001b[0m                               rhoend\u001b[39m=\u001b[39;49mrhoend, iprint\u001b[39m=\u001b[39;49miprint, maxfun\u001b[39m=\u001b[39;49mmaxfun,\n\u001b[1;32m    262\u001b[0m                               dinfo\u001b[39m=\u001b[39;49minfo)\n\u001b[1;32m    264\u001b[0m \u001b[39mif\u001b[39;00m info[\u001b[39m3\u001b[39m] \u001b[39m>\u001b[39m catol:\n\u001b[1;32m    265\u001b[0m     \u001b[39m# Check constraint violation\u001b[39;00m\n\u001b[1;32m    266\u001b[0m     info[\u001b[39m0\u001b[39m] \u001b[39m=\u001b[39m \u001b[39m4\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/seg_models/lib/python3.9/site-packages/scipy/optimize/cobyla.py:252\u001b[0m, in \u001b[0;36m_minimize_cobyla.<locals>.calcfc\u001b[0;34m(x, con)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcalcfc\u001b[39m(x, con):\n\u001b[0;32m--> 252\u001b[0m     f \u001b[39m=\u001b[39m fun(np\u001b[39m.\u001b[39;49mcopy(x), \u001b[39m*\u001b[39;49margs)\n\u001b[1;32m    253\u001b[0m     i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m    254\u001b[0m     \u001b[39mfor\u001b[39;00m size, c \u001b[39min\u001b[39;00m izip(cons_lengths, constraints):\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/seg_models/lib/python3.9/site-packages/qiskit_machine_learning/algorithms/trainable_model.py:271\u001b[0m, in \u001b[0;36mTrainableModel._get_objective.<locals>.objective\u001b[0;34m(objective_weights)\u001b[0m\n\u001b[1;32m    270\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective\u001b[39m(objective_weights):\n\u001b[0;32m--> 271\u001b[0m     objective_value \u001b[39m=\u001b[39m function\u001b[39m.\u001b[39;49mobjective(objective_weights)\n\u001b[1;32m    272\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_callback(objective_weights, objective_value)\n\u001b[1;32m    273\u001b[0m     \u001b[39mreturn\u001b[39;00m objective_value\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/seg_models/lib/python3.9/site-packages/qiskit_machine_learning/algorithms/objective_functions.py:152\u001b[0m, in \u001b[0;36mMultiClassObjectiveFunction.objective\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mobjective\u001b[39m(\u001b[39mself\u001b[39m, weights: np\u001b[39m.\u001b[39mndarray) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mfloat\u001b[39m:\n\u001b[1;32m    151\u001b[0m     \u001b[39m# probabilities is of shape (N, num_outputs)\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     probs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_neural_network_forward(weights)\n\u001b[1;32m    154\u001b[0m     num_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_neural_network\u001b[39m.\u001b[39moutput_shape[\u001b[39m0\u001b[39m]\n\u001b[1;32m    155\u001b[0m     val \u001b[39m=\u001b[39m \u001b[39m0.0\u001b[39m\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/seg_models/lib/python3.9/site-packages/qiskit_machine_learning/algorithms/objective_functions.py:102\u001b[0m, in \u001b[0;36mObjectiveFunction._neural_network_forward\u001b[0;34m(self, weights)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[39m# if we get the same weights, we don't compute the forward pass again.\u001b[39;00m\n\u001b[1;32m     98\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_forward_weights \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m (\n\u001b[1;32m     99\u001b[0m     \u001b[39mnot\u001b[39;00m np\u001b[39m.\u001b[39mall(np\u001b[39m.\u001b[39misclose(weights, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_forward_weights))\n\u001b[1;32m    100\u001b[0m ):\n\u001b[1;32m    101\u001b[0m     \u001b[39m# compute forward and cache the results for re-use in backward\u001b[39;00m\n\u001b[0;32m--> 102\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_forward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_neural_network\u001b[39m.\u001b[39;49mforward(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_X, weights)\n\u001b[1;32m    103\u001b[0m     \u001b[39m# a copy avoids keeping a reference to the same array, so we are sure we have\u001b[39;00m\n\u001b[1;32m    104\u001b[0m     \u001b[39m# different arrays on the next iteration.\u001b[39;00m\n\u001b[1;32m    105\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_last_forward_weights \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcopy(weights)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/seg_models/lib/python3.9/site-packages/qiskit_machine_learning/neural_networks/neural_network.py:224\u001b[0m, in \u001b[0;36mNeuralNetwork.forward\u001b[0;34m(self, input_data, weights)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m    211\u001b[0m     input_data: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mfloat\u001b[39m] \u001b[39m|\u001b[39m np\u001b[39m.\u001b[39mndarray \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    212\u001b[0m     weights: \u001b[39mfloat\u001b[39m \u001b[39m|\u001b[39m \u001b[39mlist\u001b[39m[\u001b[39mfloat\u001b[39m] \u001b[39m|\u001b[39m np\u001b[39m.\u001b[39mndarray \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    213\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m np\u001b[39m.\u001b[39mndarray \u001b[39m|\u001b[39m SparseArray:\n\u001b[1;32m    214\u001b[0m     \u001b[39m\"\"\"Forward pass of the network.\u001b[39;00m\n\u001b[1;32m    215\u001b[0m \n\u001b[1;32m    216\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    222\u001b[0m \u001b[39m        The result of the neural network of the shape (output_shape).\u001b[39;00m\n\u001b[1;32m    223\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 224\u001b[0m     input_, shape \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_validate_input(input_data)\n\u001b[1;32m    225\u001b[0m     weights_ \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_validate_weights(weights)\n\u001b[1;32m    226\u001b[0m     output_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward(input_, weights_)\n",
      "File \u001b[0;32m/opt/homebrew/Caskroom/miniconda/base/envs/seg_models/lib/python3.9/site-packages/qiskit_machine_learning/neural_networks/neural_network.py:132\u001b[0m, in \u001b[0;36mNeuralNetwork._validate_input\u001b[0;34m(self, input_data)\u001b[0m\n\u001b[1;32m    129\u001b[0m     \u001b[39mreturn\u001b[39;00m input_, shape\n\u001b[1;32m    131\u001b[0m \u001b[39mif\u001b[39;00m shape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m] \u001b[39m!=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_inputs:\n\u001b[0;32m--> 132\u001b[0m     \u001b[39mraise\u001b[39;00m QiskitMachineLearningError(\n\u001b[1;32m    133\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mInput data has incorrect shape, last dimension \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    134\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mis not equal to the number of inputs: \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    135\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_inputs\u001b[39m}\u001b[39;00m\u001b[39m, but got: \u001b[39m\u001b[39m{\u001b[39;00mshape[\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    136\u001b[0m     )\n\u001b[1;32m    138\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(shape) \u001b[39m==\u001b[39m \u001b[39m1\u001b[39m:\n\u001b[1;32m    139\u001b[0m     \u001b[39m# add an empty dimension for samples (batch dimension)\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     input_ \u001b[39m=\u001b[39m input_\u001b[39m.\u001b[39mreshape((\u001b[39m1\u001b[39m, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m))\n",
      "\u001b[0;31mQiskitMachineLearningError\u001b[0m: 'Input data has incorrect shape, last dimension is not equal to the number of inputs: 8, but got: 3.'"
     ]
    }
   ],
   "source": [
    "objective_func_vals = []\n",
    "plt.rcParams[\"figure.figsize\"] = (12, 6)\n",
    "classifier.fit(X_train, Y_train_one_hot)\n",
    "\n",
    "# score classifier\n",
    "print(f\"Accuracy from the train data : {np.round(100 * classifier.score(x, y), 2)}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c469f18",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "observable_7class = [SparsePauliOp.from_list([('Z' + 'I' * 63, 1)]) for _ in range(7)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81315e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "qnn_7class = EstimatorQNN(\n",
    "    circuit=circuit.decompose(),\n",
    "    observables=observable_7class,\n",
    "    input_params=feature_map.parameters,\n",
    "    weight_params=ansatz.parameters,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25eaf132",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "classifier_7class = NeuralNetworkClassifier(\n",
    "    qnn_7class,\n",
    "    optimizer=COBYLA(maxiter=200),  # Set max iterations here\n",
    "    callback=callback_graph,\n",
    ")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "seg_models",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
